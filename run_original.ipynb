{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b06bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from delphi.__main__ import run\n",
    "from delphi.config import RunConfig, CacheConfig, SamplerConfig, ConstructorConfig\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3baba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def start_run(settings):\n",
    "    cache_cfg = CacheConfig(n_tokens=settings[\"n_tokens\"], n_splits=settings[\"n_splits\"])\n",
    "\n",
    "    run_cfg = RunConfig(\n",
    "        cache_cfg=cache_cfg,\n",
    "        constructor_cfg=ConstructorConfig(),\n",
    "        sampler_cfg=SamplerConfig(),\n",
    "        model=settings[\"subject_model\"],\n",
    "        sparse_model=settings[\"sparse_model\"],\n",
    "        explainer_model=settings[\"explainer_model\"],\n",
    "        max_latents=settings[\"n_latents\"],\n",
    "        hookpoints=settings[\"hookpoints\"],\n",
    "        filter_bos=True,\n",
    "        name=settings[\"name\"],\n",
    "        verbose=True,\n",
    "        seed=22\n",
    "    )\n",
    "\n",
    "    await run(run_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6a987d",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_run = {\n",
    "    \"n_tokens\": 10_000_000,                                 # how many tokens to cache\n",
    "    \"n_splits\": 1,                                          # how many files the cache is split into\n",
    "    \"subject_model\": \"meta-llama/Llama-3.2-1B\",             # HF name of subject model\n",
    "    \"sparse_model\": \"EleutherAI/sae-Llama-3.2-1B-131k\",     # HF name of SAEs\n",
    "    \"explainer_model\": \"Qwen/Qwen2.5-32B-Instruct-AWQ\",     # HF name of explainer/interpreter model\n",
    "    \"n_latents\": 8,                                         # number of heads per layer\n",
    "    \"hookpoints\": [\"layers.15.mlp\"],                        # which layers to cache\n",
    "    \"name\": \"original_10mil\"                                # folder name of cache\n",
    "}\n",
    "\n",
    "await start_run(settings_run)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorpan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
