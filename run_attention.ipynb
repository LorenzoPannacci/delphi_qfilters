{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8c65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import shutil\n",
    "import re\n",
    "\n",
    "from delphi.attention.__main__ import run\n",
    "from delphi.config import RunConfig, CacheConfig, SamplerConfig, ConstructorConfig\n",
    "from safetensors.torch import load_file, save_file\n",
    "from pathlib import Path\n",
    "\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a8a9e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_process_cache(base_path, mode, value, abs, normalize, n_latents):\n",
    "    latents_path = base_path / \"latents\"\n",
    "    log_path = base_path / \"log\" / \"hookpoint_firing_counts.pt\"\n",
    "    firing_counts = dict()\n",
    "\n",
    "    for folder in latents_path.iterdir(): # cycle through folders (layers)\n",
    "        if folder.is_dir():\n",
    "            layer = folder.name\n",
    "            firing_counts[layer] = torch.zeros(n_latents, dtype=torch.int64)\n",
    "\n",
    "            for file in folder.glob(\"*.safetensors\"): # cycle through safetensors\n",
    "                tensor = load_file(file)\n",
    "                activations = tensor['activations'].cpu()\n",
    "                locations = tensor['locations'].cpu()\n",
    "                keep_mask_total = torch.zeros_like(activations, dtype=torch.bool)\n",
    "\n",
    "                lat_start, lat_end = list(map(int, re.findall(r\"\\d+\", file.name)))\n",
    "                \n",
    "                if abs:\n",
    "                    # get absolute value\n",
    "                    activations = activations.abs()\n",
    "                else:\n",
    "                    # shift positive and negative\n",
    "                    # activations = -activations\n",
    "                    # move to minimum zero\n",
    "                    activations = activations - activations.min()\n",
    "\n",
    "                # apply threshold\n",
    "                for i in range(0, lat_end - lat_start + 1):\n",
    "                    mask = locations[:, 2] == i\n",
    "\n",
    "                    if mask.any():\n",
    "                        layer_activations = activations[mask]\n",
    "\n",
    "                        # get threshold\n",
    "                        if mode == 'threshold':\n",
    "                            threshold = value\n",
    "\n",
    "                        elif mode == \"percentile\":\n",
    "                            np_activations = layer_activations.view(-1).numpy().astype(np.float32)\n",
    "                            threshold = np.percentile(np_activations, value)\n",
    "\n",
    "                        # apply threshold\n",
    "                        layer_keep_mask = layer_activations >= threshold\n",
    "                        keep_mask_total[mask] = layer_keep_mask\n",
    "\n",
    "                # normalize activations\n",
    "                if normalize:\n",
    "                    for i in range(0, lat_end - lat_start + 1):\n",
    "                        mask = (locations[:, 2] == i) & keep_mask_total\n",
    "                        if mask.any():\n",
    "                            layer_activations = activations[mask]\n",
    "\n",
    "                            min_val = layer_activations.min()\n",
    "                            max_val = layer_activations.max()\n",
    "                            if max_val > min_val:\n",
    "                                activations[mask] = (layer_activations - min_val) / (max_val - min_val)\n",
    "                            else:\n",
    "                                activations[mask] = torch.zeros_like(layer_activations)\n",
    "\n",
    "                # apply global keep mask\n",
    "                tensor['activations'] = activations[keep_mask_total]\n",
    "                tensor['locations'] = locations.to(torch.int32)[keep_mask_total]\n",
    "\n",
    "                # update log for layer\n",
    "                values, counts = torch.unique(tensor['locations'][:, 2], return_counts=True)                \n",
    "                firing_counts[layer][values + lat_start] = counts\n",
    "\n",
    "                # convert tensors to numpy arrays before saving\n",
    "                tensor['locations'] = tensor['locations'].to(torch.int32)\n",
    "                tensor_numpy = {k: v.cpu() for k, v in tensor.items()}\n",
    "\n",
    "                # overwrite safetensor file\n",
    "                save_file(tensor_numpy, file)\n",
    "\n",
    "    # save log\n",
    "    torch.save(firing_counts, log_path)\n",
    "\n",
    "\n",
    "def copy_folder(src, dst):\n",
    "\n",
    "    base = Path(\"./results\")\n",
    "\n",
    "    src = base / src\n",
    "    dst = base / dst\n",
    "\n",
    "    if not src.exists() or not src.is_dir():\n",
    "        raise FileNotFoundError(f\"Source folder '{src}' does not exist or is not a directory.\")\n",
    "\n",
    "    if dst.exists():\n",
    "        shutil.rmtree(dst)\n",
    "\n",
    "    shutil.copytree(src, dst)\n",
    "\n",
    "\n",
    "async def create_cache(settings):\n",
    "    cache_cfg = CacheConfig(n_tokens=settings[\"n_tokens\"], n_splits=settings[\"n_splits\"])\n",
    "\n",
    "    run_cfg = RunConfig(\n",
    "        cache_cfg=cache_cfg,\n",
    "        constructor_cfg=ConstructorConfig(),\n",
    "        sampler_cfg=SamplerConfig(),\n",
    "        model=settings[\"subject_model\"],\n",
    "        explainer_model=settings[\"explainer_model\"],\n",
    "        max_latents=settings[\"n_latents\"],\n",
    "        hookpoints=settings[\"hookpoints\"],\n",
    "        filter_bos=True,\n",
    "        name=settings[\"name\"],\n",
    "        verbose=True,\n",
    "        seed=22\n",
    "    )\n",
    "\n",
    "    await run(run_cfg, steps=2)\n",
    "\n",
    "\n",
    "async def validate(settings_run, settings):\n",
    "    # post process cache\n",
    "    name = f'{settings[\"src\"]}_{\"abs_\" if settings[\"abs\"] else \"\"}{\"norm_\" if settings[\"normalize\"] else \"\"}{\"perc\" if settings[\"method\"]==\"percentile\" else \"thrd\"}_{settings[\"value\"]}'\n",
    "    base_path = Path(\"./results\") / name\n",
    "    copy_folder(src=settings[\"src\"], dst=name)\n",
    "    post_process_cache(base_path, settings[\"method\"], settings[\"value\"], settings[\"abs\"], settings[\"normalize\"], settings_run[\"n_latents\"])\n",
    "\n",
    "    cache_cfg = CacheConfig(n_tokens=settings_run[\"n_tokens\"], n_splits=settings_run[\"n_splits\"])\n",
    "\n",
    "    run_cfg = RunConfig(\n",
    "        cache_cfg=cache_cfg,\n",
    "        constructor_cfg=ConstructorConfig(),\n",
    "        sampler_cfg=SamplerConfig(),\n",
    "        model=settings_run[\"subject_model\"],\n",
    "        explainer_model=settings_run[\"explainer_model\"],\n",
    "        max_latents=settings_run[\"n_latents\"],\n",
    "        hookpoints=settings_run[\"hookpoints\"],\n",
    "        filter_bos=True,\n",
    "        name=name,\n",
    "        verbose=True,\n",
    "        seed=22\n",
    "    )\n",
    "\n",
    "    await run(run_cfg, steps=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc42025",
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_run = {\n",
    "    \"n_tokens\": 1_000_000,                                 # how many tokens to cache\n",
    "    \"n_splits\": 1,                                         # how many files the cache is split into\n",
    "    \"subject_model\": \"meta-llama/Llama-3.2-1B\",            # HF name of subject model\n",
    "    \"explainer_model\": \"Qwen/Qwen2.5-32B-Instruct-AWQ\",    # HF name of explainer/interpreter model\n",
    "    \"n_latents\": 32,                                       # number of heads per layer\n",
    "    \"hookpoints\": [\"5\"],                                   # which layers to cache\n",
    "    \"name\": \"1mil_attn\"                                    # folder name of cache\n",
    "}\n",
    "\n",
    "settings_post_process = {\n",
    "    \"src\": \"1mil_attn\",                                    # folder name of source cache\n",
    "    \"abs\": False,                                           # apply absolute value\n",
    "    \"normalize\": False,                                     # normalize between 0 and 1\n",
    "    \"method\": \"percentile\",                                 # thresholding method\n",
    "    \"value\": 99.99,                                         # thresholding value\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60f10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "await create_cache(settings_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0cc08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "await validate(settings_run, settings_post_process)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lorpan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
